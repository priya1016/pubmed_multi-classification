{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### This notebook contains evaluations of the Bio-Bert and Roberta Model on test data.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import hamming_loss, jaccard_score,classification_report \n\nimport torch\nimport tensorflow as tf\nfrom transformers import RobertaTokenizer,BertTokenizer,BertForSequenceClassification,BertModel,TFBertModel\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n!pip install jaro-winkler","metadata":{"execution":{"iopub.status.busy":"2022-12-11T00:27:48.656486Z","iopub.execute_input":"2022-12-11T00:27:48.656941Z","iopub.status.idle":"2022-12-11T00:28:30.534176Z","shell.execute_reply.started":"2022-12-11T00:27:48.656853Z","shell.execute_reply":"2022-12-11T00:28:30.532752Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2022-12-11 00:28:06.292091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:06.293114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:06.294223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:06.295054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:06.295843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:06.296581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:06.301040: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-11 00:28:06.575580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:06.576512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:06.577288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:06.578022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:06.578735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:06.579487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:16.704698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:16.705636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:16.706367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:16.707066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:16.707823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:16.708546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13351 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-12-11 00:28:16.713121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:16.713860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13351 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Collecting jaro-winkler\n  Downloading jaro_winkler-2.0.3-py3-none-any.whl (33 kB)\nInstalling collected packages: jaro-winkler\nSuccessfully installed jaro-winkler-2.0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-11T00:28:33.698912Z","iopub.execute_input":"2022-12-11T00:28:33.700224Z","iopub.status.idle":"2022-12-11T00:28:33.748049Z","shell.execute_reply.started":"2022-12-11T00:28:33.700189Z","shell.execute_reply":"2022-12-11T00:28:33.746957Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/training-batch-800-809csv/training_batch_800_809.csv\n/kaggle/input/bert-model-saved/config.json\n/kaggle/input/bert-model-saved/tokenizer_config.json\n/kaggle/input/bert-model-saved/pytorch_model.bin\n/kaggle/input/bert-model-saved/special_tokens_map.json\n/kaggle/input/pubmed-multi-label/roberta_results.csv\n/kaggle/input/pubmed-multi-label/Classification_Report.csv\n/kaggle/input/pubmed-multi-label/train_data_loader\n/kaggle/input/pubmed-multi-label/__results__.html\n/kaggle/input/pubmed-multi-label/test_data_loader\n/kaggle/input/pubmed-multi-label/roberta_model\n/kaggle/input/pubmed-multi-label/validation_data_loader\n/kaggle/input/pubmed-multi-label/val_results.csv\n/kaggle/input/pubmed-multi-label/__notebook__.ipynb\n/kaggle/input/pubmed-multi-label/__output__.json\n/kaggle/input/pubmed-multi-label/custom.css\n/kaggle/input/pubmed-multi-label/Multi_label_Classification_Save/config.json\n/kaggle/input/pubmed-multi-label/Multi_label_Classification_Save/tokenizer_config.json\n/kaggle/input/pubmed-multi-label/Multi_label_Classification_Save/pytorch_model.bin\n/kaggle/input/pubmed-multi-label/Multi_label_Classification_Save/special_tokens_map.json\n/kaggle/input/pubmed-multi-label/Multi_label_Classification_Save/vocab.txt\n/kaggle/input/pubmed-multi-label/__results___files/__results___9_0.png\n/kaggle/input/pubmed-multi-label/__results___files/__results___31_0.png\n/kaggle/input/pubmed-multi-label/__results___files/__results___33_1.png\n/kaggle/input/pubmed-multi-label/__results___files/__results___32_1.png\n/kaggle/input/pubmed-multi-label/__results___files/__results___22_1.png\n/kaggle/input/pubmedtest/training_batch_810_819.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"device_name = tf.test.gpu_device_name()\nif device_name != '/device:GPU:0':\n    raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))","metadata":{"execution":{"iopub.status.busy":"2022-12-11T00:28:34.717143Z","iopub.execute_input":"2022-12-11T00:28:34.717517Z","iopub.status.idle":"2022-12-11T00:28:34.737266Z","shell.execute_reply.started":"2022-12-11T00:28:34.717485Z","shell.execute_reply":"2022-12-11T00:28:34.735996Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found GPU at: /device:GPU:0\n","output_type":"stream"},{"name":"stderr","text":"2022-12-11 00:28:34.719507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:34.720182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:34.720940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:34.721376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:34.722084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:34.722584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:34.723562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:34.724076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:34.724866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:34.725257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 13351 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-12-11 00:28:34.725379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-11 00:28:34.726050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:1 with 13351 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()\ntorch.cuda.get_device_name(0)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T00:28:35.424066Z","iopub.execute_input":"2022-12-11T00:28:35.425163Z","iopub.status.idle":"2022-12-11T00:28:35.442435Z","shell.execute_reply.started":"2022-12-11T00:28:35.425115Z","shell.execute_reply":"2022-12-11T00:28:35.440737Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'Tesla T4'"},"metadata":{}}]},{"cell_type":"code","source":"dataset_Name = '/kaggle/input/pubmedtest/training_batch_810_819.csv'\n\ndf= pd.read_csv(dataset_Name)#.head(1000)\n\ncols = list(df.columns)\n\n# might have to change depending on categories \nmesh_Heading_categories = cols[6:]\nnum_labels = len(mesh_Heading_categories)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T00:28:36.471991Z","iopub.execute_input":"2022-12-11T00:28:36.472397Z","iopub.status.idle":"2022-12-11T00:28:43.651356Z","shell.execute_reply.started":"2022-12-11T00:28:36.472366Z","shell.execute_reply":"2022-12-11T00:28:43.650305Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"len(mesh_Heading_categories)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T00:28:44.068726Z","iopub.execute_input":"2022-12-11T00:28:44.069456Z","iopub.status.idle":"2022-12-11T00:28:44.076282Z","shell.execute_reply.started":"2022-12-11T00:28:44.069420Z","shell.execute_reply":"2022-12-11T00:28:44.075177Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"15"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Bert Predictions ","metadata":{}},{"cell_type":"code","source":"# # df_train, df_test = train_test_split(df, random_state=32, test_size=0.20, shuffle=True)\ndf_test = df.copy()\ndf_test['one_hot_labels'] = list(df_test[mesh_Heading_categories].values)\n\ntest_labels = list(df_test.one_hot_labels.values)\nArticles_test = list(df_test.AbstractText.values)\ntest_mesh_categories = list(df_test.columns[6:21])\n\n# tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base', do_lower_case=False)\ntokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.2', do_lower_case=True)\n# tokenizer = BertTokenizer.from_pretrained('/kaggle/input/bert-model-saved/tokenizer_config.json', do_lower_case=True)\nmax_length = 128\n\ntest_encodings = tokenizer.batch_encode_plus(Articles_test,max_length=max_length,padding=True,truncation=True)\ntest_input_ids = test_encodings['input_ids']\ntest_attention_masks = test_encodings['attention_mask']\n\n\nbatch_size = 128\n# Make tensors out of data\ntest_inputs = torch.tensor(test_input_ids)\ntest_labels = torch.tensor(test_labels)\ntest_masks = torch.tensor(test_attention_masks)\n# Create test dataloader\ntest_data = TensorDataset(test_inputs, test_masks, test_labels,)# test_token_types)\ntest_sampler = SequentialSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n# Save test dataloader\ntorch.save(test_dataloader,'test_810_819_bert_data_loader')","metadata":{"execution":{"iopub.status.busy":"2022-12-11T00:28:45.712341Z","iopub.execute_input":"2022-12-11T00:28:45.712714Z","iopub.status.idle":"2022-12-11T00:47:08.072327Z","shell.execute_reply.started":"2022-12-11T00:28:45.712682Z","shell.execute_reply":"2022-12-11T00:47:08.071215Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"308d4b154a5249fc8fe24703709e350f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5136720204724541a965468839b08c53"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:207.)\n","output_type":"stream"}]},{"cell_type":"code","source":"num_labels=len(mesh_Heading_categories)\nmodel = BertForSequenceClassification.from_pretrained(\"/kaggle/input/bert-model-saved/\", num_labels=num_labels)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:54:55.582495Z","iopub.execute_input":"2022-12-11T01:54:55.582936Z","iopub.status.idle":"2022-12-11T01:54:56.904295Z","shell.execute_reply.started":"2022-12-11T01:54:55.582900Z","shell.execute_reply":"2022-12-11T01:54:56.903128Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"os.environ['TF_FORCE_GPU_ALLOW_GROWTH']='true'\nmodel.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:55:01.399900Z","iopub.execute_input":"2022-12-11T01:55:01.400338Z","iopub.status.idle":"2022-12-11T01:55:01.526737Z","shell.execute_reply.started":"2022-12-11T01:55:01.400304Z","shell.execute_reply":"2022-12-11T01:55:01.525571Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=15, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Put model in evaluation mode to evaluate loss on the validation set\nmodel.eval()\n\n#track variables\nlogit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n\n# Predict\nfor i, batch in enumerate(test_dataloader):\n    batch = tuple(t.to(device) for t in batch)\n    # Unpack the inputs from our dataloader\n    b_input_ids, b_input_mask, b_labels, = batch\n    with torch.no_grad():\n        # Forward pass\n        outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n        b_logit_pred = outs[0]\n        pred_label = torch.sigmoid(b_logit_pred)\n\n        b_logit_pred = b_logit_pred.detach().cpu().numpy()\n        pred_label = pred_label.to('cpu').numpy()\n        b_labels = b_labels.to('cpu').numpy()\n\n    tokenized_texts.append(b_input_ids)\n    logit_preds.append(b_logit_pred)\n    true_labels.append(b_labels)\n    pred_labels.append(pred_label)\n\n# Flatten outputs\ntokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T00:47:13.756401Z","iopub.execute_input":"2022-12-11T00:47:13.757049Z","iopub.status.idle":"2022-12-11T01:12:18.801746Z","shell.execute_reply.started":"2022-12-11T00:47:13.757008Z","shell.execute_reply":"2022-12-11T01:12:18.800644Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"pred_labels = [item for sublist in pred_labels for item in sublist]\ntrue_labels = [item for sublist in true_labels for item in sublist]\n# Converting flattened binary values to boolean values\ntrue_bools = [tl==1 for tl in true_labels]\n\npred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:12:18.803295Z","iopub.execute_input":"2022-12-11T01:12:18.803944Z","iopub.status.idle":"2022-12-11T01:12:19.367156Z","shell.execute_reply.started":"2022-12-11T01:12:18.803903Z","shell.execute_reply":"2022-12-11T01:12:19.366057Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import jaro\nfrom sklearn.metrics import hamming_loss, jaccard_score, classification_report, multilabel_confusion_matrix, f1_score, accuracy_score, log_loss \nfrom Levenshtein import distance as levenshtein_distance\n\n\ndef eval_test_report(true_bools,pred_bools, model_name):\n    '''\n    true_label: numpy array consisting of list (length 15 = num_labels) of actual labels [1,0,1,...,0]\n    pred_label: numpy array consisting of list (length 15 = num_labels) of predicted labels [1,0,1,...,0]\n    '''\n    \n    report_dict = {}\n    report_dict['jaccard'] = 100.0*jaccard_score(true_bools,pred_bools, average=\"macro\")\n    report_dict['f1_score_micro'] = 100.0*f1_score(true_bools, pred_bools,average='micro')\n    report_dict['f1_score_macro'] = 100.0*f1_score(true_bools, pred_bools,average='macro')\n    report_dict['accuracy_score'] = 100.0*accuracy_score(true_bools, pred_bools)\n    \n    # lower the better\n    report_dict['hamming_loss*'] = hamming_loss(true_bools, pred_bools)\n    report_dict['log_loss*'] = log_loss(true_bools,pred_bools)\n    \n    # similarity by string matching\n    pred_str = [''.join(list(map(str, (list(x))))) for x in list(pred_bools)]\n    true_str = [''.join(list(map(str, (list(x))))) for x in list(true_bools)]\n\n    sim = []\n    i = 0\n    while i < len(pred_str):\n        sim.append(jaro.jaro_winkler_metric(true_str[i],pred_str[i]))\n        i+=1\n    \n    report_dict['jaro_mean'] = 100.0*np.mean(sim)\n    \n    sim = []\n    i = 0\n    while i < len(pred_str):\n        sim.append(levenshtein_distance(true_str[i],pred_str[i]))\n        i+=1\n    \n    report_dict['lev_mean*'] = np.mean(sim)\n    \n#     print(classification_report(true_bools,pred_bools,target_names=test_mesh_categories)\n    final = {model_name: report_dict}\n    \n    return pd.DataFrame(final)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:12:19.368779Z","iopub.execute_input":"2022-12-11T01:12:19.369212Z","iopub.status.idle":"2022-12-11T01:12:19.555143Z","shell.execute_reply.started":"2022-12-11T01:12:19.369142Z","shell.execute_reply":"2022-12-11T01:12:19.553795Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Final Report\nreport_bert = eval_test_report(true_bools,pred_bools,model_name = 'bio-bert')\nreport_bert.to_csv(\"bert_evaluation.csv\")\nreport_bert","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:19:06.193899Z","iopub.execute_input":"2022-12-11T01:19:06.195006Z","iopub.status.idle":"2022-12-11T01:19:50.849994Z","shell.execute_reply.started":"2022-12-11T01:19:06.194967Z","shell.execute_reply":"2022-12-11T01:19:50.848838Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                 bio-bert\naccuracy_score  17.964407\nf1_score_macro  76.402175\nf1_score_micro  85.572135\nhamming_loss*    0.111592\njaccard         64.170488\njaro_mean       92.031463\nlev_mean*        6.597424\nlog_loss*       42.382964","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bio-bert</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy_score</th>\n      <td>17.964407</td>\n    </tr>\n    <tr>\n      <th>f1_score_macro</th>\n      <td>76.402175</td>\n    </tr>\n    <tr>\n      <th>f1_score_micro</th>\n      <td>85.572135</td>\n    </tr>\n    <tr>\n      <th>hamming_loss*</th>\n      <td>0.111592</td>\n    </tr>\n    <tr>\n      <th>jaccard</th>\n      <td>64.170488</td>\n    </tr>\n    <tr>\n      <th>jaro_mean</th>\n      <td>92.031463</td>\n    </tr>\n    <tr>\n      <th>lev_mean*</th>\n      <td>6.597424</td>\n    </tr>\n    <tr>\n      <th>log_loss*</th>\n      <td>42.382964</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## segment (20%) of test data from train set\n\ndata = pd.read_csv(\"/kaggle/input/training-batch-800-809csv/training_batch_800_809.csv\")\ndf_train, df_test = train_test_split(data, random_state=32, test_size=0.20, shuffle=True)\n\ndf_test['one_hot_labels'] = list(df_test[mesh_Heading_categories].values)\n\ntest_labels = list(df_test.one_hot_labels.values)\nArticles_test = list(df_test.AbstractText.values)\ntest_mesh_categories = list(df_test.columns[6:21])\n\n# tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base', do_lower_case=False)\ntokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.2', do_lower_case=True)\n# tokenizer = BertTokenizer.from_pretrained('/kaggle/input/bert-model-saved/tokenizer_config.json', do_lower_case=True)\nmax_length = 128\n\ntest_encodings = tokenizer.batch_encode_plus(Articles_test,max_length=max_length,padding=True,truncation=True)\ntest_input_ids = test_encodings['input_ids']\ntest_attention_masks = test_encodings['attention_mask']\n\n\nbatch_size = 128\n# Make tensors out of data\ntest_inputs = torch.tensor(test_input_ids)\ntest_labels = torch.tensor(test_labels)\ntest_masks = torch.tensor(test_attention_masks)\n# Create test dataloader\ntest_data = TensorDataset(test_inputs, test_masks, test_labels,)# test_token_types)\ntest_sampler = SequentialSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n# Save test dataloader\n# torch.save(test_dataloader,'test_810_819_bert_data_loader')\n\n# Put model in evaluation mode to evaluate loss on the validation set\nmodel.eval()\n\n#track variables\nlogit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n\n# Predict\nfor i, batch in enumerate(test_dataloader):\n    batch = tuple(t.to(device) for t in batch)\n    # Unpack the inputs from our dataloader\n    b_input_ids, b_input_mask, b_labels, = batch\n    with torch.no_grad():\n        # Forward pass\n        outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n        b_logit_pred = outs[0]\n        pred_label = torch.sigmoid(b_logit_pred)\n\n        b_logit_pred = b_logit_pred.detach().cpu().numpy()\n        pred_label = pred_label.to('cpu').numpy()\n        b_labels = b_labels.to('cpu').numpy()\n\n    tokenized_texts.append(b_input_ids)\n    logit_preds.append(b_logit_pred)\n    true_labels.append(b_labels)\n    pred_labels.append(pred_label)\n\n# Flatten outputs\ntokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n\npred_labels = [item for sublist in pred_labels for item in sublist]\ntrue_labels = [item for sublist in true_labels for item in sublist]\n# Converting flattened binary values to boolean values\ntrue_bools = [tl==1 for tl in true_labels]\n\npred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n\n# Final Report\nreport_bert_mini_test = eval_test_report(true_bools,pred_bools,model_name = 'bio-bert')\nreport_bert_mini_test","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:55:09.592030Z","iopub.execute_input":"2022-12-11T01:55:09.592411Z","iopub.status.idle":"2022-12-11T02:04:01.938850Z","shell.execute_reply.started":"2022-12-11T01:55:09.592379Z","shell.execute_reply":"2022-12-11T02:04:01.937786Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                 bio-bert\naccuracy_score  18.375586\nf1_score_macro  76.443762\nf1_score_micro  85.698372\nhamming_loss*    0.110315\njaccard         64.270727\njaro_mean       92.142947\nlev_mean*        6.525314\nlog_loss*       41.979689","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bio-bert</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy_score</th>\n      <td>18.375586</td>\n    </tr>\n    <tr>\n      <th>f1_score_macro</th>\n      <td>76.443762</td>\n    </tr>\n    <tr>\n      <th>f1_score_micro</th>\n      <td>85.698372</td>\n    </tr>\n    <tr>\n      <th>hamming_loss*</th>\n      <td>0.110315</td>\n    </tr>\n    <tr>\n      <th>jaccard</th>\n      <td>64.270727</td>\n    </tr>\n    <tr>\n      <th>jaro_mean</th>\n      <td>92.142947</td>\n    </tr>\n    <tr>\n      <th>lev_mean*</th>\n      <td>6.525314</td>\n    </tr>\n    <tr>\n      <th>log_loss*</th>\n      <td>41.979689</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Roberta Predictions","metadata":{}},{"cell_type":"code","source":"model = torch.load(\"/kaggle/input/pubmed-multi-label/roberta_model\")","metadata":{"execution":{"iopub.status.busy":"2022-12-11T00:02:40.187262Z","iopub.execute_input":"2022-12-11T00:02:40.187779Z","iopub.status.idle":"2022-12-11T00:02:40.193372Z","shell.execute_reply.started":"2022-12-11T00:02:40.187733Z","shell.execute_reply":"2022-12-11T00:02:40.191902Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# # df_train, df_test = train_test_split(df, random_state=32, test_size=0.20, shuffle=True)\ndf_test = df.copy()\ndf_test['one_hot_labels'] = list(df_test[mesh_Heading_categories].values)\n\ntest_labels = list(df_test.one_hot_labels.values)\nArticles_test = list(df_test.AbstractText.values)\ntest_mesh_categories = list(df_test.columns[6:21])\n\ntokenizer = RobertaTokenizer.from_pretrained('distilroberta-base', do_lower_case=False)\n# tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.2', do_lower_case=True)\n\nmax_length = 128\n\ntest_encodings = tokenizer.batch_encode_plus(Articles_test,max_length=max_length,padding=True,truncation=True)\ntest_input_ids = test_encodings['input_ids']\ntest_attention_masks = test_encodings['attention_mask']\n\n\nbatch_size = 128\n# Make tensors out of data\ntest_inputs = torch.tensor(test_input_ids)\ntest_labels = torch.tensor(test_labels)\ntest_masks = torch.tensor(test_attention_masks)\n# Create test dataloader\ntest_data = TensorDataset(test_inputs, test_masks, test_labels,)aa# test_token_types)\ntest_sampler = SequentialSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n# Save test dataloader\ntorch.save(test_dataloader,'test_810_819_roberta_data_loader')","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:20:12.266748Z","iopub.execute_input":"2022-12-11T01:20:12.267429Z","iopub.status.idle":"2022-12-11T01:25:49.793670Z","shell.execute_reply.started":"2022-12-11T01:20:12.267393Z","shell.execute_reply":"2022-12-11T01:25:49.792652Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a1aa6350ec14497bca08dbbca1dfc44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2408c44604c4fc4b1a5af2b53f7649a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9f9831e10bc4a468d4f23031748af61"}},"metadata":{}}]},{"cell_type":"code","source":"# Put model in evaluation mode to evaluate loss on the validation set\nmodel.eval()\n\n#track variables\nlogit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n\n# Predict\nfor i, batch in enumerate(test_dataloader):\n    batch = tuple(t.to(device) for t in batch)\n    # Unpack the inputs from our dataloader\n    b_input_ids, b_input_mask, b_labels, = batch\n    with torch.no_grad():\n        # Forward pass\n        outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n        b_logit_pred = outs[0]\n        pred_label = torch.sigmoid(b_logit_pred)\n\n        b_logit_pred = b_logit_pred.detach().cpu().numpy()\n        pred_label = pred_label.to('cpu').numpy()\n        b_labels = b_labels.to('cpu').numpy()\n\n    tokenized_texts.append(b_input_ids)\n    logit_preds.append(b_logit_pred)\n    true_labels.append(b_labels)\n    pred_labels.append(pred_label)\n\n# Flatten outputs\ntokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:35:34.988731Z","iopub.execute_input":"2022-12-11T01:35:34.989497Z","iopub.status.idle":"2022-12-11T01:47:49.845463Z","shell.execute_reply.started":"2022-12-11T01:35:34.989460Z","shell.execute_reply":"2022-12-11T01:47:49.844372Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"pred_labels = [item for sublist in pred_labels for item in sublist]\ntrue_labels = [item for sublist in true_labels for item in sublist]\n# Converting flattened binary values to boolean values\ntrue_bools = [tl==1 for tl in true_labels]\n\npred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:48:42.339305Z","iopub.execute_input":"2022-12-11T01:48:42.339696Z","iopub.status.idle":"2022-12-11T01:48:42.908222Z","shell.execute_reply.started":"2022-12-11T01:48:42.339654Z","shell.execute_reply":"2022-12-11T01:48:42.907118Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import jaro\nfrom sklearn.metrics import hamming_loss, jaccard_score, classification_report, multilabel_confusion_matrix, f1_score, accuracy_score, log_loss \nfrom Levenshtein import distance as levenshtein_distance\n\n\ndef eval_test_report(true_bools,pred_bools, model_name):\n    '''\n    true_label: numpy array consisting of list (length 15 = num_labels) of actual labels [1,0,1,...,0]\n    pred_label: numpy array consisting of list (length 15 = num_labels) of predicted labels [1,0,1,...,0]\n    '''\n    \n    report_dict = {}\n    report_dict['jaccard'] = 100.0*jaccard_score(true_bools,pred_bools, average=\"macro\")\n    report_dict['f1_score_micro'] = 100.0*f1_score(true_bools, pred_bools,average='micro')\n    report_dict['f1_score_macro'] = 100.0*f1_score(true_bools, pred_bools,average='macro')\n    report_dict['accuracy_score'] = 100.0*accuracy_score(true_bools, pred_bools)\n    \n    # lower the better\n    report_dict['hamming_loss*'] = hamming_loss(true_bools, pred_bools)\n    report_dict['log_loss*'] = log_loss(true_bools,pred_bools)\n    \n    # similarity by string matching\n    pred_str = [''.join(list(map(str, (list(x))))) for x in list(pred_bools)]\n    true_str = [''.join(list(map(str, (list(x))))) for x in list(true_bools)]\n\n    sim = []\n    i = 0\n    while i < len(pred_str):\n        sim.append(jaro.jaro_winkler_metric(true_str[i],pred_str[i]))\n        i+=1\n    \n    report_dict['jaro_mean'] = 100.0*np.mean(sim)\n    \n    sim = []\n    i = 0\n    while i < len(pred_str):\n        sim.append(levenshtein_distance(true_str[i],pred_str[i]))\n        i+=1\n    \n    report_dict['lev_mean*'] = np.mean(sim)\n    \n#     print(classification_report(true_bools,pred_bools,target_names=test_mesh_categories)\n    final = {model_name: report_dict}\n    \n    return pd.DataFrame(final)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:48:44.253325Z","iopub.execute_input":"2022-12-11T01:48:44.253708Z","iopub.status.idle":"2022-12-11T01:48:44.281759Z","shell.execute_reply.started":"2022-12-11T01:48:44.253675Z","shell.execute_reply":"2022-12-11T01:48:44.280742Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Final Report\nreport_roberta = eval_test_report(true_bools,pred_bools,model_name = 'roberta')\nreport_roberta","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:48:45.254024Z","iopub.execute_input":"2022-12-11T01:48:45.255154Z","iopub.status.idle":"2022-12-11T01:49:29.707775Z","shell.execute_reply.started":"2022-12-11T01:48:45.255100Z","shell.execute_reply":"2022-12-11T01:49:29.706755Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                  roberta\naccuracy_score  16.912740\nf1_score_macro  75.320716\nf1_score_micro  85.287306\nhamming_loss*    0.114331\njaccard         63.077289\njaro_mean       91.849154\nlev_mean*        6.756530\nlog_loss*       42.206369","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roberta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy_score</th>\n      <td>16.912740</td>\n    </tr>\n    <tr>\n      <th>f1_score_macro</th>\n      <td>75.320716</td>\n    </tr>\n    <tr>\n      <th>f1_score_micro</th>\n      <td>85.287306</td>\n    </tr>\n    <tr>\n      <th>hamming_loss*</th>\n      <td>0.114331</td>\n    </tr>\n    <tr>\n      <th>jaccard</th>\n      <td>63.077289</td>\n    </tr>\n    <tr>\n      <th>jaro_mean</th>\n      <td>91.849154</td>\n    </tr>\n    <tr>\n      <th>lev_mean*</th>\n      <td>6.756530</td>\n    </tr>\n    <tr>\n      <th>log_loss*</th>\n      <td>42.206369</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"final_report = pd.concat([report_bert, report_roberta], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:49:41.454539Z","iopub.execute_input":"2022-12-11T01:49:41.454945Z","iopub.status.idle":"2022-12-11T01:49:41.460038Z","shell.execute_reply.started":"2022-12-11T01:49:41.454911Z","shell.execute_reply":"2022-12-11T01:49:41.459069Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"final_report","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:49:51.721658Z","iopub.execute_input":"2022-12-11T01:49:51.722049Z","iopub.status.idle":"2022-12-11T01:49:51.734382Z","shell.execute_reply.started":"2022-12-11T01:49:51.722016Z","shell.execute_reply":"2022-12-11T01:49:51.733163Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                 bio-bert    roberta\naccuracy_score  17.964407  16.912740\nf1_score_macro  76.402175  75.320716\nf1_score_micro  85.572135  85.287306\nhamming_loss*    0.111592   0.114331\njaccard         64.170488  63.077289\njaro_mean       92.031463  91.849154\nlev_mean*        6.597424   6.756530\nlog_loss*       42.382964  42.206369","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bio-bert</th>\n      <th>roberta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy_score</th>\n      <td>17.964407</td>\n      <td>16.912740</td>\n    </tr>\n    <tr>\n      <th>f1_score_macro</th>\n      <td>76.402175</td>\n      <td>75.320716</td>\n    </tr>\n    <tr>\n      <th>f1_score_micro</th>\n      <td>85.572135</td>\n      <td>85.287306</td>\n    </tr>\n    <tr>\n      <th>hamming_loss*</th>\n      <td>0.111592</td>\n      <td>0.114331</td>\n    </tr>\n    <tr>\n      <th>jaccard</th>\n      <td>64.170488</td>\n      <td>63.077289</td>\n    </tr>\n    <tr>\n      <th>jaro_mean</th>\n      <td>92.031463</td>\n      <td>91.849154</td>\n    </tr>\n    <tr>\n      <th>lev_mean*</th>\n      <td>6.597424</td>\n      <td>6.756530</td>\n    </tr>\n    <tr>\n      <th>log_loss*</th>\n      <td>42.382964</td>\n      <td>42.206369</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"final_report.to_csv(\"bert_roberta_results.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:49:55.651480Z","iopub.execute_input":"2022-12-11T01:49:55.652104Z","iopub.status.idle":"2022-12-11T01:49:55.660015Z","shell.execute_reply.started":"2022-12-11T01:49:55.652065Z","shell.execute_reply":"2022-12-11T01:49:55.658355Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"## segment (20%) of test data from train set\ntest_dataloader = torch.load('/kaggle/input/pubmed-multi-label/test_data_loader')\n\n# Put model in evaluation mode to evaluate loss on the validation set\nmodel.eval()\n\n#track variables\nlogit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n\n# Predict\nfor i, batch in enumerate(test_dataloader):\n    batch = tuple(t.to(device) for t in batch)\n    # Unpack the inputs from our dataloader\n    b_input_ids, b_input_mask, b_labels, = batch\n    with torch.no_grad():\n        # Forward pass\n        outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n        b_logit_pred = outs[0]\n        pred_label = torch.sigmoid(b_logit_pred)\n\n        b_logit_pred = b_logit_pred.detach().cpu().numpy()\n        pred_label = pred_label.to('cpu').numpy()\n        b_labels = b_labels.to('cpu').numpy()\n\n    tokenized_texts.append(b_input_ids)\n    logit_preds.append(b_logit_pred)\n    true_labels.append(b_labels)\n    pred_labels.append(pred_label)\n\n# Flatten outputs\ntokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n\npred_labels = [item for sublist in pred_labels for item in sublist]\ntrue_labels = [item for sublist in true_labels for item in sublist]\n# Converting flattened binary values to boolean values\ntrue_bools = [tl==1 for tl in true_labels]\n\npred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n\n\nreport_roberta_mini_test = eval_test_report(true_bools,pred_bools,model_name = 'roberta')\nreport_roberta_mini_test","metadata":{"execution":{"iopub.status.busy":"2022-12-11T01:50:27.074016Z","iopub.execute_input":"2022-12-11T01:50:27.074396Z","iopub.status.idle":"2022-12-11T01:53:08.558093Z","shell.execute_reply.started":"2022-12-11T01:50:27.074365Z","shell.execute_reply":"2022-12-11T01:53:08.556836Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                   roberta\naccuracy_score    0.062690\nf1_score_macro   27.429926\nf1_score_micro   46.018290\nhamming_loss*     0.394721\njaccard          20.137369\njaro_mean        86.065294\nlev_mean*        20.025728\nlog_loss*       125.190575","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roberta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy_score</th>\n      <td>0.062690</td>\n    </tr>\n    <tr>\n      <th>f1_score_macro</th>\n      <td>27.429926</td>\n    </tr>\n    <tr>\n      <th>f1_score_micro</th>\n      <td>46.018290</td>\n    </tr>\n    <tr>\n      <th>hamming_loss*</th>\n      <td>0.394721</td>\n    </tr>\n    <tr>\n      <th>jaccard</th>\n      <td>20.137369</td>\n    </tr>\n    <tr>\n      <th>jaro_mean</th>\n      <td>86.065294</td>\n    </tr>\n    <tr>\n      <th>lev_mean*</th>\n      <td>20.025728</td>\n    </tr>\n    <tr>\n      <th>log_loss*</th>\n      <td>125.190575</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pd.concat([report_bert_mini_test, report_roberta_mini_test], axis=1).to_csv(\"bert_roberta_mini_test.csv\")\npd.concat([report_bert_mini_test, report_roberta_mini_test], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T02:06:58.888862Z","iopub.execute_input":"2022-12-11T02:06:58.889266Z","iopub.status.idle":"2022-12-11T02:06:58.903493Z","shell.execute_reply.started":"2022-12-11T02:06:58.889232Z","shell.execute_reply":"2022-12-11T02:06:58.901889Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                 bio-bert     roberta\naccuracy_score  18.375586    0.062690\nf1_score_macro  76.443762   27.429926\nf1_score_micro  85.698372   46.018290\nhamming_loss*    0.110315    0.394721\njaccard         64.270727   20.137369\njaro_mean       92.142947   86.065294\nlev_mean*        6.525314   20.025728\nlog_loss*       41.979689  125.190575","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bio-bert</th>\n      <th>roberta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy_score</th>\n      <td>18.375586</td>\n      <td>0.062690</td>\n    </tr>\n    <tr>\n      <th>f1_score_macro</th>\n      <td>76.443762</td>\n      <td>27.429926</td>\n    </tr>\n    <tr>\n      <th>f1_score_micro</th>\n      <td>85.698372</td>\n      <td>46.018290</td>\n    </tr>\n    <tr>\n      <th>hamming_loss*</th>\n      <td>0.110315</td>\n      <td>0.394721</td>\n    </tr>\n    <tr>\n      <th>jaccard</th>\n      <td>64.270727</td>\n      <td>20.137369</td>\n    </tr>\n    <tr>\n      <th>jaro_mean</th>\n      <td>92.142947</td>\n      <td>86.065294</td>\n    </tr>\n    <tr>\n      <th>lev_mean*</th>\n      <td>6.525314</td>\n      <td>20.025728</td>\n    </tr>\n    <tr>\n      <th>log_loss*</th>\n      <td>41.979689</td>\n      <td>125.190575</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}